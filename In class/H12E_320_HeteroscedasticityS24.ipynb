{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "div.blue{\n",
    "    background-color:#e6f0ff; \n",
    "    border-radius: 5px; \n",
    "    padding: 20px;}\n",
    "</style> \n",
    "\n",
    "<style>\n",
    "div.warn {    \n",
    "    background-color: #fcf2f2;\n",
    "    border-color: #dFb5b4;\n",
    "    border-left: 5px solid #dfb5b4;\n",
    "    padding: 0.5em;\n",
    "    }\n",
    " </style>\n",
    "    \n",
    "<h1 style=\"text-align: center; color: purple;\" markdown=\"1\">Econ 320 Python: Heteroscedasticity </h1>\n",
    "<h2 style=\"text-align: center; color: purple;\" markdown=\"1\">Handout </h2>\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf \n",
    "# Important new packages for this topic\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.api as sm\n",
    "import patsy as pt\n",
    "\n",
    "from stargazer.stargazer import Stargazer\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heteroscedasticity\n",
    "\n",
    "The homoscedasticity assumptions require that the variance of the error terms is unrelated to the regressors, i.e. \n",
    "\n",
    "$$Var(u|x_1, ..., x_k)=\\sigma^2.$$ \n",
    "\n",
    "If homoscedasticity is violated, the standard errors are invalid and all inferences from t, F and other tests based on them are unreliable. In that case, we are facing heteroscedasticity in the standard errors: the circumstance in which the variability of the standard errors is unequal across the range of values of the predicted value of the dependent variable.\n",
    "\n",
    "## Heteroscedasticity-Robust Inference\n",
    "\n",
    "\n",
    "As you learned in class you need to modify the standard errors to correct for heteroscedasticity. This is having \"heteroscedasticity-robust standard errors.\" \n",
    "\n",
    "In Python, we can do this using the `statsmodels` package. Using the  argument `cov_type` in the method `.fit()` we can obtain regression results that produced several refined versions of the white formula presented in your book. (Wooldridge, 2019). \n",
    "\n",
    "Let's say that the results from your regression are stored in the object *reg.*, then the variance- covariance matrix can be calculated using \n",
    "\n",
    "* **reg.fit(cov_type='nonrobust')** or **reg.fit()** for the default homoscedasticy-based standard errors. \n",
    "* **reg.fit(cov_type='HC0')**  for the classical version of White's robust varinace-covariance matrix by Wooldridge (2019, Equation 8.4 in Section 8,2)\n",
    "* **reg.fit(cov_type='HC1')**  for the classical version of White's robust varinace-covariance matrix corrected by degrees of freedom.  \n",
    "* **reg.fit(cov_type='HC2')**  for a version with small sample correction. This isndefault behavious of Stata. \n",
    "* **reg.fit(cov_type='HC3')**  for the refined version of version White's robust variance- covariance matrix. \n",
    "\n",
    "### Example with GPA data from wooldridge\n",
    "\n",
    "For the spring semester run the regression \n",
    "\n",
    "$$ Cumulative GPA = \\beta_0 + \\beta_1SAT + \\beta_2HSpercentile + \\beta_3Totalhours + \\beta_4 female + \\beta_5 black + \\beta_6 white $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>cumgpa</td>      <th>  R-squared:         </th> <td>   0.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   39.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Apr 2025</td> <th>  Prob (F-statistic):</th> <td>3.41e-37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:38:13</td>     <th>  Log-Likelihood:    </th> <td> -238.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   366</td>      <th>  AIC:               </th> <td>   491.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   359</td>      <th>  BIC:               </th> <td>   519.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.4701</td> <td>    0.230</td> <td>    6.397</td> <td> 0.000</td> <td>    1.018</td> <td>    1.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sat</th>       <td>    0.0011</td> <td>    0.000</td> <td>    6.389</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hsperc</th>    <td>   -0.0086</td> <td>    0.001</td> <td>   -6.906</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tothrs</th>    <td>    0.0025</td> <td>    0.001</td> <td>    3.426</td> <td> 0.001</td> <td>    0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>    <td>    0.3034</td> <td>    0.059</td> <td>    5.141</td> <td> 0.000</td> <td>    0.187</td> <td>    0.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>   -0.1283</td> <td>    0.147</td> <td>   -0.870</td> <td> 0.385</td> <td>   -0.418</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>white</th>     <td>   -0.0587</td> <td>    0.141</td> <td>   -0.416</td> <td> 0.677</td> <td>   -0.336</td> <td>    0.219</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.271</td> <th>  Durbin-Watson:     </th> <td>   1.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.072</td> <th>  Jarque-Bera (JB):  </th> <td>   6.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.123</td> <th>  Prob(JB):          </th> <td>  0.0402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.601</td> <th>  Cond. No.          </th> <td>1.01e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.01e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      cumgpa      & \\textbf{  R-squared:         } &     0.401   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.391   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     39.98   \\\\\n",
       "\\textbf{Date:}             & Fri, 18 Apr 2025 & \\textbf{  Prob (F-statistic):} &  3.41e-37   \\\\\n",
       "\\textbf{Time:}             &     13:38:13     & \\textbf{  Log-Likelihood:    } &   -238.90   \\\\\n",
       "\\textbf{No. Observations:} &         366      & \\textbf{  AIC:               } &     491.8   \\\\\n",
       "\\textbf{Df Residuals:}     &         359      & \\textbf{  BIC:               } &     519.1   \\\\\n",
       "\\textbf{Df Model:}         &           6      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       1.4701  &        0.230     &     6.397  &         0.000        &        1.018    &        1.922     \\\\\n",
       "\\textbf{sat}       &       0.0011  &        0.000     &     6.389  &         0.000        &        0.001    &        0.001     \\\\\n",
       "\\textbf{hsperc}    &      -0.0086  &        0.001     &    -6.906  &         0.000        &       -0.011    &       -0.006     \\\\\n",
       "\\textbf{tothrs}    &       0.0025  &        0.001     &     3.426  &         0.001        &        0.001    &        0.004     \\\\\n",
       "\\textbf{female}    &       0.3034  &        0.059     &     5.141  &         0.000        &        0.187    &        0.420     \\\\\n",
       "\\textbf{black}     &      -0.1283  &        0.147     &    -0.870  &         0.385        &       -0.418    &        0.162     \\\\\n",
       "\\textbf{white}     &      -0.0587  &        0.141     &    -0.416  &         0.677        &       -0.336    &        0.219     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  5.271 & \\textbf{  Durbin-Watson:     } &    1.865  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.072 & \\textbf{  Jarque-Bera (JB):  } &    6.429  \\\\\n",
       "\\textbf{Skew:}          & -0.123 & \\textbf{  Prob(JB):          } &   0.0402  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.601 & \\textbf{  Cond. No.          } & 1.01e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.01e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 cumgpa   R-squared:                       0.401\n",
       "Model:                            OLS   Adj. R-squared:                  0.391\n",
       "Method:                 Least Squares   F-statistic:                     39.98\n",
       "Date:                Fri, 18 Apr 2025   Prob (F-statistic):           3.41e-37\n",
       "Time:                        13:38:13   Log-Likelihood:                -238.90\n",
       "No. Observations:                 366   AIC:                             491.8\n",
       "Df Residuals:                     359   BIC:                             519.1\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.4701      0.230      6.397      0.000       1.018       1.922\n",
       "sat            0.0011      0.000      6.389      0.000       0.001       0.001\n",
       "hsperc        -0.0086      0.001     -6.906      0.000      -0.011      -0.006\n",
       "tothrs         0.0025      0.001      3.426      0.001       0.001       0.004\n",
       "female         0.3034      0.059      5.141      0.000       0.187       0.420\n",
       "black         -0.1283      0.147     -0.870      0.385      -0.418       0.162\n",
       "white         -0.0587      0.141     -0.416      0.677      -0.336       0.219\n",
       "==============================================================================\n",
       "Omnibus:                        5.271   Durbin-Watson:                   1.865\n",
       "Prob(Omnibus):                  0.072   Jarque-Bera (JB):                6.429\n",
       "Skew:                          -0.123   Prob(JB):                       0.0402\n",
       "Kurtosis:                       3.601   Cond. No.                     1.01e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.01e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpa3 = woo.dataWoo('gpa3')\n",
    "\n",
    "# define regression model:\n",
    "reg = smf.ols(formula='cumgpa ~ sat + hsperc + tothrs + female + black + white',\n",
    "              data=gpa3, subset=(gpa3['spring'] == 1))\n",
    "results_default = reg.fit()\n",
    "\n",
    "# estimate default model (only for spring data):\n",
    "\n",
    "results_default.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>cumgpa</td>      <th>  R-squared:         </th> <td>   0.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   39.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Apr 2025</td> <th>  Prob (F-statistic):</th> <td>3.41e-37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:38:13</td>     <th>  Log-Likelihood:    </th> <td> -238.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   366</td>      <th>  AIC:               </th> <td>   491.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   359</td>      <th>  BIC:               </th> <td>   519.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.4701</td> <td>    0.230</td> <td>    6.397</td> <td> 0.000</td> <td>    1.018</td> <td>    1.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sat</th>       <td>    0.0011</td> <td>    0.000</td> <td>    6.389</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hsperc</th>    <td>   -0.0086</td> <td>    0.001</td> <td>   -6.906</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tothrs</th>    <td>    0.0025</td> <td>    0.001</td> <td>    3.426</td> <td> 0.001</td> <td>    0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>    <td>    0.3034</td> <td>    0.059</td> <td>    5.141</td> <td> 0.000</td> <td>    0.187</td> <td>    0.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>   -0.1283</td> <td>    0.147</td> <td>   -0.870</td> <td> 0.385</td> <td>   -0.418</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>white</th>     <td>   -0.0587</td> <td>    0.141</td> <td>   -0.416</td> <td> 0.677</td> <td>   -0.336</td> <td>    0.219</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.271</td> <th>  Durbin-Watson:     </th> <td>   1.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.072</td> <th>  Jarque-Bera (JB):  </th> <td>   6.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.123</td> <th>  Prob(JB):          </th> <td>  0.0402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.601</td> <th>  Cond. No.          </th> <td>1.01e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.01e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      cumgpa      & \\textbf{  R-squared:         } &     0.401   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.391   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     39.98   \\\\\n",
       "\\textbf{Date:}             & Fri, 18 Apr 2025 & \\textbf{  Prob (F-statistic):} &  3.41e-37   \\\\\n",
       "\\textbf{Time:}             &     13:38:13     & \\textbf{  Log-Likelihood:    } &   -238.90   \\\\\n",
       "\\textbf{No. Observations:} &         366      & \\textbf{  AIC:               } &     491.8   \\\\\n",
       "\\textbf{Df Residuals:}     &         359      & \\textbf{  BIC:               } &     519.1   \\\\\n",
       "\\textbf{Df Model:}         &           6      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       1.4701  &        0.230     &     6.397  &         0.000        &        1.018    &        1.922     \\\\\n",
       "\\textbf{sat}       &       0.0011  &        0.000     &     6.389  &         0.000        &        0.001    &        0.001     \\\\\n",
       "\\textbf{hsperc}    &      -0.0086  &        0.001     &    -6.906  &         0.000        &       -0.011    &       -0.006     \\\\\n",
       "\\textbf{tothrs}    &       0.0025  &        0.001     &     3.426  &         0.001        &        0.001    &        0.004     \\\\\n",
       "\\textbf{female}    &       0.3034  &        0.059     &     5.141  &         0.000        &        0.187    &        0.420     \\\\\n",
       "\\textbf{black}     &      -0.1283  &        0.147     &    -0.870  &         0.385        &       -0.418    &        0.162     \\\\\n",
       "\\textbf{white}     &      -0.0587  &        0.141     &    -0.416  &         0.677        &       -0.336    &        0.219     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  5.271 & \\textbf{  Durbin-Watson:     } &    1.865  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.072 & \\textbf{  Jarque-Bera (JB):  } &    6.429  \\\\\n",
       "\\textbf{Skew:}          & -0.123 & \\textbf{  Prob(JB):          } &   0.0402  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.601 & \\textbf{  Cond. No.          } & 1.01e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.01e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 cumgpa   R-squared:                       0.401\n",
       "Model:                            OLS   Adj. R-squared:                  0.391\n",
       "Method:                 Least Squares   F-statistic:                     39.98\n",
       "Date:                Fri, 18 Apr 2025   Prob (F-statistic):           3.41e-37\n",
       "Time:                        13:38:13   Log-Likelihood:                -238.90\n",
       "No. Observations:                 366   AIC:                             491.8\n",
       "Df Residuals:                     359   BIC:                             519.1\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.4701      0.230      6.397      0.000       1.018       1.922\n",
       "sat            0.0011      0.000      6.389      0.000       0.001       0.001\n",
       "hsperc        -0.0086      0.001     -6.906      0.000      -0.011      -0.006\n",
       "tothrs         0.0025      0.001      3.426      0.001       0.001       0.004\n",
       "female         0.3034      0.059      5.141      0.000       0.187       0.420\n",
       "black         -0.1283      0.147     -0.870      0.385      -0.418       0.162\n",
       "white         -0.0587      0.141     -0.416      0.677      -0.336       0.219\n",
       "==============================================================================\n",
       "Omnibus:                        5.271   Durbin-Watson:                   1.865\n",
       "Prob(Omnibus):                  0.072   Jarque-Bera (JB):                6.429\n",
       "Skew:                          -0.123   Prob(JB):                       0.0402\n",
       "Kurtosis:                       3.601   Cond. No.                     1.01e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.01e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate model with White SE (only for spring data):\n",
    "results_white = reg.fit()\n",
    "results_default.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intercept', 'sat', 'hsperc', 'tothrs', 'female', 'black', 'white']\n"
     ]
    }
   ],
   "source": [
    "# estimate model with refined White SE (only for spring data):\n",
    "results_refined = reg.fit(cov_type='HC3')\n",
    "\n",
    "#pay attention to the different standard errors the betas do not change\n",
    "#with robust correction\n",
    "variable_names = results_refined.params.index.tolist()\n",
    "print(variable_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference \n",
    "### T-test  \n",
    "\n",
    "We are putting toguether the three models the results assuming homoskedasticity and assuming heteroskedasticity. ( Yes it can also be written heteroscedasticity) in a stargazer table. See that the coefficnets remain the same, the standard errors change. In this case we still reject the null hypothesis, this is not always the case. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td colspan=\"3\"><em>Dependent variable: cumgpa</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>1.470<sup>***</sup></td><td>1.470<sup>***</sup></td><td>1.470<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.230)</td><td>(0.230)</td><td>(0.229)</td></tr>\n",
       "<tr><td style=\"text-align:left\">sat</td><td>0.001<sup>***</sup></td><td>0.001<sup>***</sup></td><td>0.001<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.000)</td><td>(0.000)</td><td>(0.000)</td></tr>\n",
       "<tr><td style=\"text-align:left\">hsperc</td><td>-0.009<sup>***</sup></td><td>-0.009<sup>***</sup></td><td>-0.009<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.001)</td><td>(0.001)</td><td>(0.001)</td></tr>\n",
       "<tr><td style=\"text-align:left\">tothrs</td><td>0.003<sup>***</sup></td><td>0.003<sup>***</sup></td><td>0.003<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.001)</td><td>(0.001)</td><td>(0.001)</td></tr>\n",
       "<tr><td style=\"text-align:left\">female</td><td>0.303<sup>***</sup></td><td>0.303<sup>***</sup></td><td>0.303<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.059)</td><td>(0.059)</td><td>(0.060)</td></tr>\n",
       "<tr><td style=\"text-align:left\">black</td><td>-0.128<sup></sup></td><td>-0.128<sup></sup></td><td>-0.128<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.147)</td><td>(0.147)</td><td>(0.128)</td></tr>\n",
       "<tr><td style=\"text-align:left\">white</td><td>-0.059<sup></sup></td><td>-0.059<sup></sup></td><td>-0.059<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.141)</td><td>(0.141)</td><td>(0.120)</td></tr>\n",
       "\n",
       "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>366</td><td>366</td><td>366</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.401</td><td>0.401</td><td>0.401</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.391</td><td>0.391</td><td>0.391</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.469 (df=359)</td><td>0.469 (df=359)</td><td>0.469 (df=359)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>39.982<sup>***</sup> (df=6; 359)</td><td>39.982<sup>***</sup> (df=6; 359)</td><td>38.284<sup>***</sup> (df=6; 359)</td></tr>\n",
       "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put all results in stargazer table and \n",
    "models = Stargazer([results_default, results_white, results_refined])\n",
    "models.covariate_order(['Intercept', 'sat', 'hsperc', 'tothrs', 'female', 'black', 'white'])\n",
    "HTML(models.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The F- test \n",
    "\n",
    "For the joint significance of all the coefficients you can check results for the F test on the regression table or  stargazer table. \n",
    "\n",
    "For other joint hypothesis like \n",
    "\n",
    "$$H_0: \\beta_5 = 0 \\: \\&  \\: \\beta_6=0$$\n",
    "\n",
    "See examples below. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fstat_default: 0.679604195607341\n",
      "\n",
      "fpval_default: 0.5074683622584049\n",
      "\n",
      "fstat_hc3: 0.6724692957656635\n",
      "\n",
      "fpval_hc3: 0.5110883633440992\n",
      "\n",
      "fstat_hc0: 0.7477969818036214\n",
      "\n",
      "fpval_hc0: 0.4741442714738484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definition of model and hypotheses:\n",
    "reg = smf.ols(formula='cumgpa ~ sat + hsperc + tothrs + female + black + white',\n",
    "              data=gpa3, subset=(gpa3['spring'] == 1))\n",
    "hypotheses = ['black = 0', 'white = 0']\n",
    "\n",
    "# F-Tests using different variance-covariance formulas:\n",
    "# ususal VCOV:\n",
    "results_default = reg.fit()\n",
    "ftest_default = results_default.f_test(hypotheses)\n",
    "fstat_default = ftest_default.statistic\n",
    "fpval_default = ftest_default.pvalue\n",
    "print(f'fstat_default: {fstat_default}\\n')\n",
    "print(f'fpval_default: {fpval_default}\\n')\n",
    "\n",
    "# refined White VCOV:\n",
    "results_hc3 = reg.fit(cov_type='HC3')\n",
    "ftest_hc3 = results_hc3.f_test(hypotheses)\n",
    "fstat_hc3 = ftest_hc3.statistic\n",
    "fpval_hc3 = ftest_hc3.pvalue\n",
    "print(f'fstat_hc3: {fstat_hc3}\\n')\n",
    "print(f'fpval_hc3: {fpval_hc3}\\n')\n",
    "\n",
    "# classical White VCOV:\n",
    "results_hc0 = reg.fit(cov_type='HC0')\n",
    "ftest_hc0 = results_hc0.f_test(hypotheses)\n",
    "fstat_hc0 = ftest_hc0.statistic\n",
    "fpval_hc0 = ftest_hc0.pvalue\n",
    "print(f'fstat_hc0: {fstat_hc0}\\n')\n",
    "print(f'fpval_hc0: {fpval_hc0}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct for Heteroscedasticity in Homework Exercice\n",
    "### 1\n",
    "Run the model for the `sleep75` data set as appears in the book and test if the variance depends on the gender variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Table 1: Regression on Wages and Heterocedasticity Correction <br><table style=\"text-align:center\"><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td colspan=\"2\"><em>Dependent variable: np.log(wage)</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Model 1</td><td colspan=\"1\">Model 2 </td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>4.670<sup>***</sup></td><td>4.670<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.068)</td><td>(0.070)</td></tr>\n",
       "<tr><td style=\"text-align:left\">educ</td><td>0.080<sup>***</sup></td><td>0.080<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.004)</td><td>(0.004)</td></tr>\n",
       "<tr><td style=\"text-align:left\">exper</td><td>0.080<sup>***</sup></td><td>0.080<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.007)</td><td>(0.007)</td></tr>\n",
       "<tr><td style=\"text-align:left\">expersq</td><td>-0.002<sup>***</sup></td><td>-0.002<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.000)</td><td>(0.000)</td></tr>\n",
       "<tr><td style=\"text-align:left\">married_d</td><td>0.124<sup>***</sup></td><td>0.124<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.016)</td><td>(0.017)</td></tr>\n",
       "<tr><td style=\"text-align:left\">black</td><td>-0.214<sup>***</sup></td><td>-0.214<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.017)</td><td>(0.017)</td></tr>\n",
       "\n",
       "<td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>3010</td><td>3010</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.256</td><td>0.256</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.255</td><td>0.255</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.383 (df=3004)</td><td>0.383 (df=3004)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>206.766<sup>***</sup> (df=5; 3004)</td><td>204.964<sup>***</sup> (df=5; 3004)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"2\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Card 1995 data: \n",
    "card = pd.read_stata('card.dta')\n",
    "def dummy(x):\n",
    "    if x==1:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "card['married_d']=card[\"married\"].apply(dummy)\n",
    "#df, meta = prs.read_dta('card.dta', apply_value_formats=True)\n",
    "\n",
    "s1= smf.ols(formula='np.log(wage) ~ educ + exper + expersq + married_d + black', data=card).fit()\n",
    "s2= smf.ols(formula='np.log(wage) ~ educ + exper + expersq + married_d + black', \n",
    "            data=card).fit(cov_type = 'HC3')\n",
    "\n",
    "models = Stargazer([s1, s2])\n",
    "models.title('Table 1: Regression on Wages and Heterocedasticity Correction ')\n",
    "models.custom_columns(['Model 1', 'Model 2 '], [1, 1])\n",
    "models.covariate_order(['Intercept', 'educ' , 'exper' , 'expersq', 'married_d','black'])\n",
    "HTML(models.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 \n",
    "Use the data in `HPRICE1` to obtain the heteroskedasticity-robust standard errors for equation\n",
    "\n",
    "$$price = \\beta_0 + \\beta_1*lotsize + \\beta_2*sqrft + \\beta_3*bdrms $$ \n",
    "\n",
    "Discuss any important differences with the usual standard errors. \n",
    "(ii)\tRepeat part (i) for equation \n",
    "$$log(price) = log(lotsize) + log(sqrft) + bdrms$$.\n",
    "(iii)\tWhat does this example suggest about heteroskedasticity and the transformation used for the dependent variable?\n",
    "\n",
    "**Take the log-transform of the dependent variable\n",
    "Taking the log transform of the dependent variable is one of the most commonly used techniques for not only linearizing the dependent variable y but for also 'dampening down' the heteroscedastic variance (if it exists) in y.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hprice1 = woo.dataWoo('hprice1')\n",
    "results=smf.ols('price ~ lotsize + sqrft + bdrms', data=hprice1).fit()\n",
    "# Refined White heteroscedasticity-robust SE:\n",
    "results_rob=smf.ols('price ~ lotsize + sqrft + bdrms', data=hprice1).fit(cov_type='HC3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td></tr>\n",
       "<tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>-1.297<sup>**</sup></td><td>-1.297<sup></sup></td><td>-1.297<sup>**</sup></td><td>-21.770<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.651)</td><td>(0.850)</td><td>(0.651)</td><td>(41.033)</td></tr>\n",
       "<tr><td style=\"text-align:left\">bdrms</td><td>0.037<sup></sup></td><td>0.037<sup></sup></td><td>0.037<sup></sup></td><td>13.853<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.028)</td><td>(0.036)</td><td>(0.028)</td><td>(11.562)</td></tr>\n",
       "<tr><td style=\"text-align:left\">lotsize</td><td></td><td></td><td></td><td>0.002<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td>(0.007)</td></tr>\n",
       "<tr><td style=\"text-align:left\">np.log(lotsize)</td><td>0.168<sup>***</sup></td><td>0.168<sup>***</sup></td><td>0.168<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.038)</td><td>(0.053)</td><td>(0.038)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">np.log(sqrft)</td><td>0.700<sup>***</sup></td><td>0.700<sup>***</sup></td><td>0.700<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.093)</td><td>(0.121)</td><td>(0.093)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">sqrft</td><td></td><td></td><td></td><td>0.123<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td>(0.041)</td></tr>\n",
       "\n",
       "<td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>88</td><td>88</td><td>88</td><td>88</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.643</td><td>0.643</td><td>0.643</td><td>0.672</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.630</td><td>0.630</td><td>0.630</td><td>0.661</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.185 (df=84)</td><td>0.185 (df=84)</td><td>0.185 (df=84)</td><td>59.833 (df=84)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>50.424<sup>***</sup> (df=3; 84)</td><td>44.824<sup>***</sup> (df=3; 84)</td><td>50.424<sup>***</sup> (df=3; 84)</td><td>19.544<sup>***</sup> (df=3; 84)</td></tr>\n",
       "<tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"4\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultslog=smf.ols(\"np.log(price)~np.log(lotsize)+np.log(sqrft)+bdrms\", data=hprice1).fit()\n",
    "resultslog_rob=smf.ols(\"np.log(price)~np.log(lotsize)+np.log(sqrft)+bdrms\", \n",
    "                       data=hprice1).fit(cov_type='HC3')\n",
    "\n",
    "# Refined White heteroscedasticity-robust SE:\n",
    "# put all results in stargazer table and \n",
    "modelslog = Stargazer([resultslog, resultslog_rob,resultslog,results_rob])\n",
    "#models.covariate_order(['Intercept','female' , 'educ' , 'exper', 'tenure', 'married',])\n",
    "HTML(modelslog.render_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook H12E_320_HeteroscedasticityS24.ipynb to html\n",
      "[NbConvertApp] Writing 304036 bytes to H12E_320_HeteroscedasticityS24.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html H12E_320_HeteroscedasticityS24.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "<hr />\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\">ECON320 Python Programming Laboratory</a></p>\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\">Professor <em> Paloma Lopez de mesa Moyano</em></a></p>\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\"><span style=\"color: #6666FF;\"><em>paloma.moyano@emory.edu</em></span></p>\n",
    "\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\">Department of Economics</a></p>\n",
    "<p style=\"font-family:palatino; text-align: center; color: #012169;font-size: 15px\">Emory University</a></p>\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
